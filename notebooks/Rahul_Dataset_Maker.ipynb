{"cells":[{"cell_type":"markdown","metadata":{"id":"rmCPmqFL6hCQ"},"source":["# üìä Dataset Maker by Hollowstrawberry\n","\n","This is based on the work of [Kohya-ss](https://github.com/kohya-ss/sd-scripts) and [Linaqruf](https://colab.research.google.com/github/Linaqruf/kohya-trainer/blob/main/kohya-LoRA-dreambooth.ipynb). Thank you!"]},{"cell_type":"markdown","metadata":{"id":"VP6WhGSaMj7q"},"source":["### ‚≠ï Disclaimer\n","The purpose of this document is to research bleeding-edge technologies in the field of machine learning inference.  \n","Please read and follow the [Google Colab guidelines](https://research.google.com/colaboratory/faq.html) and its [Terms of Service](https://research.google.com/colaboratory/tos_v3.html)."]},{"cell_type":"markdown","metadata":{"id":"-rdgF2AWLS2h"},"source":["| |GitHub|üá¨üáß English|üá™üá∏ Spanish|\n","|:--|:-:|:-:|:-:|\n","| üè† **Homepage** | [![GitHub](https://raw.githubusercontent.com/hollowstrawberry/kohya-colab/main/assets/github.svg)](https://github.com/hollowstrawberry/kohya-colab) | | |\n","| üìä **Dataset Maker** | [![GitHub](https://raw.githubusercontent.com/hollowstrawberry/kohya-colab/main/assets/github.svg)](https://github.com/hollowstrawberry/kohya-colab/blob/main/Dataset_Maker.ipynb) | [![Open in Colab](https://raw.githubusercontent.com/hollowstrawberry/kohya-colab/main/assets/colab-badge.svg)](https://colab.research.google.com/github/hollowstrawberry/kohya-colab/blob/main/Dataset_Maker.ipynb) | [![Abrir en Colab](https://raw.githubusercontent.com/hollowstrawberry/kohya-colab/main/assets/colab-badge-spanish.svg)](https://colab.research.google.com/github/hollowstrawberry/kohya-colab/blob/main/Spanish_Dataset_Maker.ipynb) |\n","| ‚≠ê **Lora Trainer** | [![GitHub](https://raw.githubusercontent.com/hollowstrawberry/kohya-colab/main/assets/github.svg)](https://github.com/hollowstrawberry/kohya-colab/blob/main/Lora_Trainer.ipynb) | [![Open in Colab](https://raw.githubusercontent.com/hollowstrawberry/kohya-colab/main/assets/colab-badge.svg)](https://colab.research.google.com/github/hollowstrawberry/kohya-colab/blob/main/Lora_Trainer.ipynb) | [![Abrir en Colab](https://raw.githubusercontent.com/hollowstrawberry/kohya-colab/main/assets/colab-badge-spanish.svg)](https://colab.research.google.com/github/hollowstrawberry/kohya-colab/blob/main/Spanish_Lora_Trainer.ipynb) |\n","| üåü **XL Lora Trainer** | [![GitHub](https://raw.githubusercontent.com/hollowstrawberry/kohya-colab/main/assets/github.svg)](https://github.com/hollowstrawberry/kohya-colab/blob/main/Lora_Trainer_XL.ipynb) | [![Open in Colab](https://raw.githubusercontent.com/hollowstrawberry/kohya-colab/main/assets/colab-badge.svg)](https://colab.research.google.com/github/hollowstrawberry/kohya-colab/blob/main/Lora_Trainer_XL.ipynb) |  |"]},{"cell_type":"code","execution_count":1,"metadata":{"cellView":"form","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":19348,"status":"ok","timestamp":1713046211643,"user":{"displayName":"PS Rahul","userId":"02961155526492638026"},"user_tz":-120},"id":"cBa7KdewQ4BU","outputId":"21471f28-8edb-48ea-85da-6578d40930be"},"outputs":[{"name":"stdout","output_type":"stream","text":["üìÇ Connecting to Google Drive...\n","Mounted at /content/drive\n","‚úÖ Project ppzocketv2 is ready!\n"]}],"source":["import os\n","from IPython import get_ipython\n","from IPython.display import display, Markdown\n","\n","COLAB = True\n","\n","if COLAB:\n","  from google.colab.output import clear as clear_output\n","else:\n","  from IPython.display import clear_output\n","\n","#@title ## üö© Start Here\n","\n","#@markdown ### 1Ô∏è‚É£ Setup\n","#@markdown This cell will load some requirements and create the necessary folders in your Google Drive. <p>\n","#@markdown Your project name can't contain spaces but it can contain a single / to make a subfolder in your dataset.\n","project_name = \"ppzocketv2\" #@param {type:\"string\"}\n","project_name = project_name.strip()\n","#@markdown The folder structure doesn't matter and is purely for comfort. Make sure to always pick the same one. I like organizing by project.\n","folder_structure = \"Organize by project (MyDrive/Loras/project_name/dataset)\" #@param [\"Organize by category (MyDrive/lora_training/datasets/project_name)\", \"Organize by project (MyDrive/Loras/project_name/dataset)\"]\n","\n","if not project_name or any(c in project_name for c in \" .()\\\"'\\\\\") or project_name.count(\"/\") > 1:\n","  print(\"Please write a valid project_name.\")\n","else:\n","  if COLAB and not os.path.exists('/content/drive'):\n","    from google.colab import drive\n","    print(\"üìÇ Connecting to Google Drive...\")\n","    drive.mount('/content/drive')\n","\n","  project_base = project_name if \"/\" not in project_name else project_name[:project_name.rfind(\"/\")]\n","  project_subfolder = project_name if \"/\" not in project_name else project_name[project_name.rfind(\"/\")+1:]\n","\n","  root_dir = \"/content\" if COLAB else \"~/Loras\"\n","  deps_dir = os.path.join(root_dir, \"deps\")\n","\n","  if \"/Loras\" in folder_structure:\n","    main_dir      = os.path.join(root_dir, \"drive/MyDrive/Loras\") if COLAB else root_dir\n","    config_folder = os.path.join(main_dir, project_base)\n","    images_folder = os.path.join(main_dir, project_base, \"dataset\")\n","    if \"/\" in project_name:\n","      images_folder = os.path.join(images_folder, project_subfolder)\n","  else:\n","    main_dir      = os.path.join(root_dir, \"drive/MyDrive/lora_training\") if COLAB else root_dir\n","    config_folder = os.path.join(main_dir, \"config\", project_name)\n","    images_folder = os.path.join(main_dir, \"datasets\", project_name)\n","\n","  for dir in [main_dir, deps_dir, images_folder, config_folder]:\n","    os.makedirs(dir, exist_ok=True)\n","\n","  print(f\"‚úÖ Project {project_name} is ready!\")\n","  step1_installed_flag = True\n"]},{"cell_type":"code","execution_count":2,"metadata":{"cellView":"form","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":207478,"status":"ok","timestamp":1713046486992,"user":{"displayName":"PS Rahul","userId":"02961155526492638026"},"user_tz":-120},"id":"sl4FD7Mz-uea","outputId":"a53cf25a-499a-4cbf-a6b2-ca9af9122db8"},"outputs":[{"name":"stdout","output_type":"stream","text":["üìä Captioning complete. Here are 10 example captions from your dataset:\n","a pair of wooden shoes with straps on them\n","a bottle of perfume sitting on a table\n","a pair of purple and black shoes hanging from a string\n","a jar of body butter next to a plant and rocks\n","a watch with a black face and orange hands\n","a smart watch sitting on top of a table next to a phone\n","a bottle of cbd oil and a jar of cbd cream\n","a bottle of beer sitting on a table\n","three different flavors of soda sitting on a pool\n","three orange suitcases sitting on a stone bench\n","\n"]}],"source":["if \"step1_installed_flag\" not in globals():\n","  raise Exception(\"Please run step 1 first!\")\n","\n","#@markdown ### 4Ô∏è‚É£ Tag your images\n","#@markdown We will be using AI to automatically tag your images, specifically [Waifu Diffusion](https://huggingface.co/SmilingWolf/wd-v1-4-swinv2-tagger-v2) in the case of anime and [BLIP](https://huggingface.co/spaces/Salesforce/BLIP) in the case of photos.\n","#@markdown Giving tags/captions to your images allows for much better training. This process should take a couple minutes. <p>\n","method = \"Photo captions\" #@param [\"Anime tags\", \"Photo captions\"]\n","#@markdown **Anime:** The threshold is the minimum level of confidence the tagger must have in order to include a tag. Lower threshold = More tags. Recommended 0.35 to 0.5\n","tag_threshold = 0.35 #@param {type:\"slider\", min:0.0, max:1.0, step:0.01}\n","blacklist_tags = \"\" #@param {type:\"string\"}\n","#@markdown **Photos:** The minimum and maximum length of tokens/words in each caption.\n","caption_min = 10 #@param {type:\"number\"}\n","caption_max = 75 #@param {type:\"number\"}\n","\n","%env PYTHONPATH=/env/python\n","os.chdir(root_dir)\n","kohya = \"/content/kohya-trainer\"\n","if not os.path.exists(kohya):\n","  !git clone https://github.com/kohya-ss/sd-scripts {kohya}\n","  os.chdir(kohya)\n","  !git reset --hard 9a67e0df390033a89f17e70df5131393692c2a55\n","  os.chdir(root_dir)\n","\n","if \"tags\" in method:\n","  if \"step4a_installed_flag\" not in globals():\n","    print(\"\\nüè≠ Installing dependencies...\\n\")\n","    !pip install accelerate==0.15.0 diffusers[torch]==0.10.2 einops==0.6.0 tensorflow transformers safetensors huggingface-hub torchvision albumentations jax==0.4.23 jaxlib==0.4.23\n","    if not get_ipython().__dict__['user_ns']['_exit_code']:\n","      clear_output()\n","      step4a_installed_flag = True\n","    else:\n","      print(\"‚ùå Error installing dependencies, trying to continue anyway...\")\n","\n","  print(\"\\nüö∂‚Äç‚ôÇÔ∏è Launching program...\\n\")\n","\n","  os.environ['TF_CPP_MIN_LOG_LEVEL'] = '2'\n","  %env PYTHONPATH={kohya}\n","  !python {kohya}/finetune/tag_images_by_wd14_tagger.py \\\n","    {images_folder} \\\n","    --repo_id=SmilingWolf/wd-v1-4-swinv2-tagger-v2 \\\n","    --model_dir={root_dir} \\\n","    --thresh={tag_threshold} \\\n","    --batch_size=8 \\\n","    --caption_extension=.txt \\\n","    --force_download\n","\n","  if not get_ipython().__dict__['user_ns']['_exit_code']:\n","    print(\"removing underscores and blacklist...\")\n","    blacklisted_tags = [t.strip() for t in blacklist_tags.split(\",\")]\n","    from collections import Counter\n","    top_tags = Counter()\n","    for txt in [f for f in os.listdir(images_folder) if f.lower().endswith(\".txt\")]:\n","      with open(os.path.join(images_folder, txt), 'r') as f:\n","        tags = [t.strip() for t in f.read().split(\",\")]\n","        tags = [t.replace(\"_\", \" \") if len(t) > 3 else t for t in tags]\n","        tags = [t for t in tags if t not in blacklisted_tags]\n","      top_tags.update(tags)\n","      with open(os.path.join(images_folder, txt), 'w') as f:\n","        f.write(\", \".join(tags))\n","\n","    %env PYTHONPATH=/env/python\n","    clear_output()\n","    print(f\"üìä Tagging complete. Here are the top 50 tags in your dataset:\")\n","    print(\"\\n\".join(f\"{k} ({v})\" for k, v in top_tags.most_common(50)))\n","\n","\n","else: # Photos\n","  if \"step4b_installed_flag\" not in globals():\n","    print(\"\\nüè≠ Installing dependencies...\\n\")\n","    !pip install timm==0.6.12 fairscale==0.4.13 transformers==4.26.0 requests==2.28.2 accelerate==0.15.0 diffusers[torch]==0.10.2 einops==0.6.0 safetensors==0.2.6 jax==0.4.23 jaxlib==0.4.23\n","    if not get_ipython().__dict__['user_ns']['_exit_code']:\n","      clear_output()\n","      step4b_installed_flag = True\n","    else:\n","      print(\"‚ùå Error installing dependencies, trying to continue anyway...\")\n","\n","  print(\"\\nüö∂‚Äç‚ôÇÔ∏è Launching program...\\n\")\n","\n","  os.chdir(kohya)\n","  %env PYTHONPATH={kohya}\n","  !python {kohya}/finetune/make_captions.py \\\n","    {images_folder} \\\n","    --beam_search \\\n","    --max_data_loader_n_workers=2 \\\n","    --batch_size=8 \\\n","    --min_length={caption_min} \\\n","    --max_length={caption_max} \\\n","    --caption_extension=.txt\n","\n","  if not get_ipython().__dict__['user_ns']['_exit_code']:\n","    import random\n","    captions = [f for f in os.listdir(images_folder) if f.lower().endswith(\".txt\")]\n","    sample = []\n","    for txt in random.sample(captions, min(10, len(captions))):\n","      with open(os.path.join(images_folder, txt), 'r') as f:\n","        sample.append(f.read())\n","\n","    os.chdir(root_dir)\n","    %env PYTHONPATH=/env/python\n","    clear_output()\n","    print(f\"üìä Captioning complete. Here are {len(sample)} example captions from your dataset:\")\n","    print(\"\".join(sample))\n"]},{"cell_type":"code","execution_count":3,"metadata":{"cellView":"form","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":912,"status":"ok","timestamp":1713046605626,"user":{"displayName":"PS Rahul","userId":"02961155526492638026"},"user_tz":-120},"id":"WBFik7accyDz","outputId":"bb8edeaf-d187-4cc0-afc0-d902def180fa"},"outputs":[{"name":"stdout","output_type":"stream","text":["\n","üìé Applied new activation tag(s): ppzocketv2\n","\n","‚úÖ Done! Check your updated tags in the Extras below.\n"]}],"source":["if \"step1_installed_flag\" not in globals():\n","  raise Exception(\"Please run step 1 first!\")\n","\n","#@markdown ### 5Ô∏è‚É£ Curate your tags\n","#@markdown Modify your dataset's tags. You can run this cell multiple times with different parameters. <p>\n","\n","#@markdown Put an activation tag at the start of every text file. This is useful to make learning better and activate your Lora easier. Set `keep_tokens` to 1 when training.<p>\n","#@markdown Common tags that are removed such as hair color, etc. will be \"absorbed\" by your activation tag.\n","global_activation_tag = \"ppzocketv2\" #@param {type:\"string\"}\n","remove_tags = \"\" #@param {type:\"string\"}\n","#@markdown &nbsp;\n","\n","#@markdown In this advanced section, you can search text files containing matching tags, and replace them with less/more/different tags. If you select the checkbox below, any extra tags will be put at the start of the file, letting you assign different activation tags to different parts of your dataset. Still, you may want a more advanced tool for this.\n","search_tags = \"\" #@param {type:\"string\"}\n","replace_with = \"\" #@param {type:\"string\"}\n","search_mode = \"OR\" #@param [\"OR\", \"AND\"]\n","new_becomes_activation_tag = False #@param {type:\"boolean\"}\n","#@markdown These may be useful sometimes. Will remove existing activation tags, be careful.\n","sort_alphabetically = False #@param {type:\"boolean\"}\n","remove_duplicates = False #@param {type:\"boolean\"}\n","\n","def split_tags(tagstr):\n","  return [s.strip() for s in tagstr.split(\",\") if s.strip()]\n","\n","activation_tag_list = split_tags(global_activation_tag)\n","remove_tags_list = split_tags(remove_tags)\n","search_tags_list = split_tags(search_tags)\n","replace_with_list = split_tags(replace_with)\n","replace_new_list = [t for t in replace_with_list if t not in search_tags_list]\n","\n","replace_with_list = [t for t in replace_with_list if t not in replace_new_list]\n","replace_new_list.reverse()\n","activation_tag_list.reverse()\n","\n","remove_count = 0\n","replace_count = 0\n","\n","for txt in [f for f in os.listdir(images_folder) if f.lower().endswith(\".txt\")]:\n","\n","  with open(os.path.join(images_folder, txt), 'r') as f:\n","    tags = [s.strip() for s in f.read().split(\",\")]\n","\n","  if remove_duplicates:\n","    tags = list(set(tags))\n","  if sort_alphabetically:\n","    tags.sort()\n","\n","  for rem in remove_tags_list:\n","    if rem in tags:\n","      remove_count += 1\n","      tags.remove(rem)\n","\n","  if \"AND\" in search_mode and all(r in tags for r in search_tags_list) \\\n","      or \"OR\" in search_mode and any(r in tags for r in search_tags_list):\n","    replace_count += 1\n","    for rem in search_tags_list:\n","      if rem in tags:\n","        tags.remove(rem)\n","    for add in replace_with_list:\n","      if add not in tags:\n","        tags.append(add)\n","    for new in replace_new_list:\n","      if new_becomes_activation_tag:\n","        if new in tags:\n","          tags.remove(new)\n","        tags.insert(0, new)\n","      else:\n","        if new not in tags:\n","          tags.append(new)\n","\n","  for act in activation_tag_list:\n","    if act in tags:\n","      tags.remove(act)\n","    tags.insert(0, act)\n","\n","  with open(os.path.join(images_folder, txt), 'w') as f:\n","    f.write(\", \".join(tags))\n","\n","if global_activation_tag:\n","  print(f\"\\nüìé Applied new activation tag(s): {', '.join(activation_tag_list)}\")\n","if remove_tags:\n","  print(f\"\\nüöÆ Removed {remove_count} tags.\")\n","if search_tags:\n","  print(f\"\\nüí´ Replaced in {replace_count} files.\")\n","print(\"\\n‚úÖ Done! Check your updated tags in the Extras below.\")\n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"HuJB7BGAyZCw"},"outputs":[],"source":["#@markdown ### 6Ô∏è‚É£ Ready\n","#@markdown You should be ready to [train your Lora](https://colab.research.google.com/github/hollowstrawberry/kohya-colab/blob/main/Lora_Trainer.ipynb)!\n","\n","from IPython.display import Markdown, display\n","display(Markdown(f\"### ü¶Ä [Click here to open the Lora trainer](https://colab.research.google.com/github/hollowstrawberry/kohya-colab/blob/main/Lora_Trainer.ipynb)\"))\n"]},{"cell_type":"markdown","metadata":{"id":"gDB9GXRONfiU"},"source":["## *Ô∏è‚É£ Extras"]},{"cell_type":"code","execution_count":4,"metadata":{"cellView":"form","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":590,"status":"ok","timestamp":1713046610688,"user":{"displayName":"PS Rahul","userId":"02961155526492638026"},"user_tz":-120},"id":"xEsqOglcc6hA","outputId":"7c16c449-3679-4dcf-e0d0-3858810b3442"},"outputs":[{"name":"stdout","output_type":"stream","text":["üìä Top 50 tags:\n","ppzocketv2 (65)\n","a purse with a chain on a white surface (2)\n","a cup of coffee is being dropped into the air (1)\n","a camera with a lens on a black surface (1)\n","a black apple watch with a blue sky background (1)\n","a pair of red and white sneakers on a red background (1)\n","a pair of sunglasses sitting on top of a table (1)\n","a pair of white sneakers on a black background (1)\n","a table with a stool in front of it (1)\n","a car is shown in the dark on the road (1)\n","a plant is sitting on a table next to a cabinet (1)\n","a couch with a pillow and some lemons on the floor (1)\n","a pair of wooden shoes with straps on them (1)\n","a bottle of hemp oil sitting on a table (1)\n","a pair of sneakers with colorful laces on them (1)\n","a pair of shoes with wheels on a white platform (1)\n","a hand holding a pink flamingo purse (1)\n","a pair of black and white shoes with a flower on the heel (1)\n","a bottle of ginski vodka on a white surface (1)\n","two people holding cups of coffee with the word dunkin donuts on them (1)\n","a pair of sneakers are lit up on a light (1)\n","a purse with a zipper on it sitting on a table (1)\n","a bottle of cbd oil and a jar of cbd cream (1)\n","a pair of black and white shoes on top of a box (1)\n","three different flavors of soda sitting on a pool (1)\n","a pair of white high heels on a wooden table (1)\n","a white car parked on a dirt road (1)\n","a close up of a vw buggy with water droplets (1)\n","a pocket watch sitting on a table with a bunch of coins (1)\n","a pair of sunglasses with a black frame (1)\n","a close up of a metal object on a black surface (1)\n","a pile of different types of skin care products (1)\n","a blue suitcase sitting on a wooden bench (1)\n","a white wine glass on a pink background (1)\n","a jar of coffee sitting on top of a table (1)\n","a silver car driving down a road next to a field of sunflowers (1)\n","a vase sitting on a marble block in a room (1)\n","a mascara bottle sitting on top of a blue surface (1)\n","two mascaras sitting on a bed of red petals (1)\n","a bottle of beer sitting on a table (1)\n","a watch sitting on top of a wooden dresser (1)\n","a jar of body butter next to a plant and rocks (1)\n","a skateboard leaning against a yellow wall (1)\n","three pieces of luggage sitting on a step (1)\n","a bottle of perfume sitting on a table (1)\n","a couple of chairs that are sitting in a room (1)\n","a pair of red and white shoes hanging from a yellow wall (1)\n","a close up of a gaming headset with a microphone (1)\n","a computer monitor sitting on top of a desk (1)\n","a chair with a wooden frame and a grey seat (1)\n"]}],"source":["if \"step1_installed_flag\" not in globals():\n","  raise Exception(\"Please run step 1 first!\")\n","\n","#@markdown ### üìà Analyze Tags\n","#@markdown Perhaps you need another look at your dataset.\n","show_top_tags = 50 #@param {type:\"number\"}\n","\n","from collections import Counter\n","top_tags = Counter()\n","\n","for txt in [f for f in os.listdir(images_folder) if f.lower().endswith(\".txt\")]:\n","  with open(os.path.join(images_folder, txt), 'r') as f:\n","    top_tags.update([s.strip() for s in f.read().split(\",\")])\n","\n","top_tags = Counter(top_tags)\n","print(f\"üìä Top {show_top_tags} tags:\")\n","for k, v in top_tags.most_common(show_top_tags):\n","  print(f\"{k} ({v})\")"]},{"cell_type":"code","execution_count":null,"metadata":{"cellView":"form","id":"x56xQYwuOz2V"},"outputs":[],"source":["#@markdown ### üìÇ Unzip dataset\n","#@markdown It's much slower to upload individual files to your Drive, so you may want to upload a zip if you have your dataset in your computer.\n","zip = \"/content/drive/MyDrive/Loras/example.zip\" #@param {type:\"string\"}\n","extract_to = \"/content/drive/MyDrive/Loras/example/dataset\" #@param {type:\"string\"}\n","\n","import os, zipfile\n","\n","if not os.path.exists('/content/drive'):\n","  from google.colab import drive\n","  print(\"üìÇ Connecting to Google Drive...\")\n","  drive.mount('/content/drive')\n","\n","os.makedirs(extract_to, exist_ok=True)\n","\n","with zipfile.ZipFile(zip, 'r') as f:\n","  f.extractall(extract_to)\n","\n","print(\"‚úÖ Done\")\n"]},{"cell_type":"code","execution_count":null,"metadata":{"cellView":"form","id":"dLetTcLVOvAE"},"outputs":[],"source":["#@markdown ### üî¢ Count datasets\n","#@markdown Google Drive makes it impossible to count the files in a folder, so this will show you the file counts in all folders and subfolders.\n","folder = \"/content/drive/MyDrive/Loras\" #@param {type:\"string\"}\n","\n","import os\n","from google.colab import drive\n","\n","if not os.path.exists('/content/drive'):\n","    print(\"üìÇ Connecting to Google Drive...\\n\")\n","    drive.mount('/content/drive')\n","\n","tree = {}\n","exclude = (\"_logs\", \"/output\")\n","for i, (root, dirs, files) in enumerate(os.walk(folder, topdown=True)):\n","  dirs[:] = [d for d in dirs if all(ex not in d for ex in exclude)]\n","  images = len([f for f in files if f.lower().endswith((\".png\", \".jpg\", \".jpeg\"))])\n","  captions = len([f for f in files if f.lower().endswith(\".txt\")])\n","  others = len(files) - images - captions\n","  path = root[folder.rfind(\"/\")+1:]\n","  tree[path] = None if not images else f\"{images:>4} images | {captions:>4} captions |\"\n","  if tree[path] and others:\n","    tree[path] += f\" {others:>4} other files\"\n","\n","pad = max(len(k) for k in tree)\n","print(\"\\n\".join(f\"üìÅ{k.ljust(pad)} | {v}\" for k, v in tree.items() if v))\n"]},{"cell_type":"code","execution_count":null,"metadata":{"cellView":"form","id":"y6PKW-LIr214"},"outputs":[],"source":["if \"step1_installed_flag\" not in globals():\n","  raise Exception(\"Please run step 1 first!\")\n","\n","#@markdown ### üöÆ Clean folder\n","#@markdown Careful! Deletes all non-image files in the project folder.\n","\n","!find {images_folder} -type f ! \\( -name '*.png' -o -name '*.jpg' -o -name '*.jpeg' \\) -delete\n"]}],"metadata":{"accelerator":"GPU","colab":{"provenance":[{"file_id":"https://github.com/hollowstrawberry/kohya-colab/blob/main/Dataset_Maker.ipynb","timestamp":1713045639405}]},"gpuClass":"standard","kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"name":"python"}},"nbformat":4,"nbformat_minor":0}
